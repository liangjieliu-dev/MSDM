{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5e6579b-a544-4e8a-ae4b-27296858e96d",
   "metadata": {},
   "source": [
    "# MSDM5054 HW1 \n",
    "## Written by LIU, Liangjie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4b7bcf-c02e-43d4-a17c-be4104fd4da6",
   "metadata": {},
   "source": [
    "## Problem 1: Basic Knowledge\n",
    "## Answers:\n",
    "### 1.\n",
    "Wrong. Overfitting happens when a model captures not only the underlying patterns in the training data but also the noise. This results in excellent performance on training data but poor generalization to unseen data. While a training error of zero is a strong indicator of overfitting, overfitting can still occur even if the training error is greater than zero. This is particularly true in scenarios where the model is excessively complex relative to the amount of data, leading it to model the noise alongside the signal.\n",
    "### 2.\n",
    "The variance of KNN decreases as K increases. K represents the number of nearest neighbors considered when making a prediction. In the context of model performance, variance refers to how much the model’s predictions fluctuate with different training datasets.\n",
    "\n",
    "A larger K means the prediction is based on a broader set of neighbors, which smooths out the decision boundary. The model becomes less sensitive to fluctuations or noise in the training data, leading to more stable predictions across different datasets. \n",
    "### 3.\n",
    "The expected misclassification error of the Bayes Classifier is:\n",
    "\n",
    "$$\n",
    "\\text{Expected Error} = \\int \\left[1 - \\max_{j} q_j(x)\\right] p(x) \\, dx\n",
    "$$\n",
    "\n",
    "For each x, assign it to the class j with the highest posterior probability  $q_j(x)$ . If the true class is j, the probability of correct classification is  $q_j(x)$ . Thus, the probability of misclassification for x is  $1 - \\max_{j} q_j(x)$. Integrate the misclassification probability over all possible  x, weighted by the density  p(x).\n",
    "\n",
    "### 4.\n",
    "Proof:\n",
    "\n",
    "1.\tMinimize the Sum of Squared Residuals:\n",
    "$$\n",
    "SSR = \\sum_{i=1}^{n} e_i^2 = \\sum_{i=1}^{n} \\left(Y_i - \\hat{\\beta}_0 - \\hat{\\beta}_1 X_i\\right)^2\n",
    "$$\n",
    "2.\tTake the Partial Derivative with respect to $\\hat{\\beta}_0$ and set it to zero:\n",
    "  \n",
    "$$\n",
    "\\frac{\\partial SSR}{\\partial \\hat{\\beta}_0} = -2 \\sum_{i=1}^{n} \\left(Y_i - \\hat{\\beta}_0 - \\hat{\\beta}_1 X_i\\right) = 0\n",
    "$$\n",
    "\n",
    "Simplify to:\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^{n} \\left(Y_i - \\hat{\\beta}_0 - \\hat{\\beta}_1 X_i\\right) = 0\n",
    "$$\n",
    "\n",
    "Which implies:\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^{n} e_i = 0\n",
    "$$\n",
    "\n",
    "\n",
    "Multiple Linear Regression: The sum of residuals is also zero. Just like simple linear regression. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Proof:\n",
    "\n",
    "1.\tMinimize the Sum of Squared Residuals:\n",
    "$$\n",
    "SSR = \\sum_{i=1}^{n} e_i^2 = \\sum_{i=1}^{n} \\left(Y_i - \\hat{\\beta}_0 - \\hat{\\beta}_1 X_{i1} - \\hat{\\beta}_2 X_{i2} - \\cdots - \\hat{\\beta}_p X_{ip}\\right)^2\n",
    "$$\n",
    "2.\tTake the Partial Derivative with respect to $\\hat{\\beta}_0$ and set it to zero:\n",
    "  \n",
    "$$\n",
    "\\frac{\\partial SSR}{\\partial \\hat{\\beta}_0} = -2 \\sum_{i=1}^{n} \\left(Y_i - \\hat{\\beta}_0 - \\hat{\\beta}_1 X_{i1} - \\hat{\\beta}_2 X_{i2} - \\cdots - \\hat{\\beta}_p X_{ip}\\right) = 0\n",
    "$$\n",
    "\n",
    "Simplify to:\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^{n} \\left(Y_i - \\hat{\\beta}_0 - \\hat{\\beta}_1 X_{i1} - \\hat{\\beta}_2 X_{i2} - \\cdots - \\hat{\\beta}_p X_{ip}\\right) = 0\n",
    "$$\n",
    "\n",
    "Which implies:\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^{n} e_i = 0\n",
    "$$\n",
    "\n",
    "This indicates that under the Ordinary Least Squares estimates, the sum of the residuals is zero.\n",
    "\n",
    "### 5.\n",
    "We can use R² to compare the performance of the two models.\n",
    "\n",
    "R²: Measures the proportion of variance in the dependent variable that is predictable from the independent variables.\n",
    "\n",
    "Adjusted R²: Adjusts R² based on the number of predictors in the model, penalizing for adding variables that do not improve the model sufficiently. It is particularly useful when models have different numbers of predictors.\n",
    "\n",
    "When comparing models with the same number of predictors, R² provides a direct comparison of the proportion of variance explained without needing adjustment for differing model complexities.\n",
    "\n",
    "### 6.\n",
    "Linear Regression\n",
    "\n",
    "Advantages:\n",
    "\n",
    "1. Easy to understand and interpret the relationship between predictors and the response variable through coefficients.\n",
    "2. Generally fast to train and make predictions, even on large datasets.\n",
    "3. A foundational method with a rich theoretical background and numerous extensions.\n",
    "\n",
    "Disadvantages:\n",
    "\n",
    "1. Assumes a linear relationship between predictors and the response, which may not hold in real-world data.\n",
    "2. Outliers can disproportionately influence the model parameters, leading to biased estimates.\n",
    "3. Cannot naturally capture interactions or complex non-linear relationships without feature engineering.\n",
    "\n",
    "KNN Regression\n",
    "\n",
    "Advantages:\n",
    "\n",
    "1. Can model complex and non-linear relationships without assuming a specific functional form.\n",
    "2. The model is essentially the training data, leading to instant updates when new data is added.\n",
    "3. Easy to grasp the concept of making predictions based on local neighborhoods.\n",
    "\n",
    "Disadvantages:\n",
    "1. Requires calculating distances to all training points for each prediction, which can be slow with large datasets.\n",
    "2. Requires careful preprocessing to ensure that all features contribute appropriately to distance calculations.\n",
    "3. Selecting an optimal K is crucial; too small K can lead to overfitting, while too large K can oversmooth the predictions.\n",
    "4. Unlike linear regression, KNN does not provide explicit relationships between predictors and the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b46cdfc-33f5-497c-876c-7219570a1a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2928, 21)\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:        Life expectancy   R-squared:                       0.820\n",
      "Model:                            OLS   Adj. R-squared:                  0.819\n",
      "Method:                 Least Squares   F-statistic:                     664.0\n",
      "Date:                Fri, 20 Sep 2024   Prob (F-statistic):               0.00\n",
      "Time:                        23:47:54   Log-Likelihood:                -8239.5\n",
      "No. Observations:                2928   AIC:                         1.652e+04\n",
      "Df Residuals:                    2907   BIC:                         1.665e+04\n",
      "Df Model:                          20                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===================================================================================================\n",
      "                                      coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------------\n",
      "const                              74.4478     34.761      2.142      0.032       6.290     142.606\n",
      "Year                               -0.0090      0.017     -0.518      0.604      -0.043       0.025\n",
      "Adult Mortality                    -0.0198      0.001    -24.856      0.000      -0.021      -0.018\n",
      "infant deaths                       0.0994      0.008     11.797      0.000       0.083       0.116\n",
      "Alcohol                             0.0609      0.026      2.331      0.020       0.010       0.112\n",
      "percentage expenditure           8.755e-05   8.47e-05      1.033      0.301   -7.85e-05       0.000\n",
      "Hepatitis B                        -0.0140      0.004     -3.569      0.000      -0.022      -0.006\n",
      "Measles                         -1.978e-05   7.66e-06     -2.581      0.010   -3.48e-05   -4.75e-06\n",
      "BMI                                 0.0441      0.005      8.878      0.000       0.034       0.054\n",
      "under-five deaths                  -0.0744      0.006    -12.045      0.000      -0.087      -0.062\n",
      "Polio                               0.0288      0.004      6.437      0.000       0.020       0.038\n",
      "Total expenditure                   0.0560      0.035      1.620      0.105      -0.012       0.124\n",
      "Diphtheria                          0.0404      0.005      8.571      0.000       0.031       0.050\n",
      "HIV/AIDS                           -0.4707      0.018    -26.663      0.000      -0.505      -0.436\n",
      "GDP                              3.291e-05    1.3e-05      2.527      0.012    7.38e-06    5.84e-05\n",
      "Population                       2.712e-10   1.69e-09      0.160      0.873   -3.05e-09    3.59e-09\n",
      "thinness  1-19 years               -0.0817      0.050     -1.622      0.105      -0.181       0.017\n",
      "thinness 5-9 years                  0.0063      0.050      0.127      0.899      -0.091       0.104\n",
      "Income composition of resources     5.6090      0.645      8.689      0.000       4.343       6.875\n",
      "Schooling                           0.6741      0.043     15.814      0.000       0.591       0.758\n",
      "Status_Developing                  -1.5832      0.270     -5.860      0.000      -2.113      -1.054\n",
      "==============================================================================\n",
      "Omnibus:                      135.692   Durbin-Watson:                   0.694\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              398.153\n",
      "Skew:                          -0.175   Prob(JB):                     3.49e-87\n",
      "Kurtosis:                       4.772   Cond. No.                     2.57e+10\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.57e+10. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# Problem 2: Investigation of Life Expectancy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import math\n",
    "\n",
    "data = pd.read_csv(\"Life Expectancy Data.csv\")\n",
    "\n",
    "data.columns = data.columns.str.strip()\n",
    "\n",
    "data = data.drop(columns=['Country'])\n",
    "\n",
    "data = data.dropna(subset=['Life expectancy'])\n",
    "\n",
    "print(data.shape)\n",
    "\n",
    "data['Status'] = data['Status'].astype('category')\n",
    "data = pd.get_dummies(data, columns=['Status'], drop_first=True)\n",
    "data['Status_Developing'] = data['Status_Developing'].astype(int)\n",
    "\n",
    "X = data.drop(columns=['Life expectancy'])\n",
    "X_filled = X.fillna(X.mean())\n",
    "X = sm.add_constant(X_filled)\n",
    "y = data['Life expectancy']\n",
    "\n",
    "full_model = sm.OLS(y, X).fit()\n",
    "\n",
    "print(full_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dadb65e5-934c-479e-83bf-107a2f602c34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "95% confidence interval:\n",
      "\n",
      "Adult Mortality: [-0.021350525396983937, -0.01822835814112676]\n",
      "HIV/AIDS: [-0.5053295472183785, -0.4360966923109017]\n",
      "\n",
      "Adult Mortality has negative impact on the life expectancy.\n",
      "HIV/AIDS has negative impact on the life expectancy.\n"
     ]
    }
   ],
   "source": [
    "conf_intervals = full_model.conf_int(alpha=0.05)\n",
    "print(\"\\n95% confidence interval:\")\n",
    "adult_mortality_ci = conf_intervals.loc['Adult Mortality']\n",
    "hiv_aids_ci = conf_intervals.loc['HIV/AIDS']\n",
    "\n",
    "print(\"\\nAdult Mortality:\", adult_mortality_ci.tolist())\n",
    "print(\"HIV/AIDS:\", hiv_aids_ci.tolist())\n",
    "\n",
    "if adult_mortality_ci[0] < 0 and adult_mortality_ci[1] < 0:\n",
    "    print(\"\\nAdult Mortality has negative impact on the life expectancy.\")\n",
    "else:\n",
    "    print(\"\\nAdult Mortality has no impact on the life expectancy.\")\n",
    "\n",
    "if hiv_aids_ci[0] < 0 and hiv_aids_ci[1] < 0:\n",
    "    print(\"HIV/AIDS has negative impact on the life expectancy.\")\n",
    "else:\n",
    "    print(\"HIV/AIDS has no impact on the life expectancy.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3601ffb9-a91f-4167-bc29-0965bd32e1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Schooling 97% confidence intervals: [0.58155514 0.76666183]\n",
      "Alcohol 97% confidence intervals: [0.00418148 0.11756867]\n",
      "Schooling has positive impact on the life expectancy.\n",
      "Alcohol has positive impact on the life expectancy.\n"
     ]
    }
   ],
   "source": [
    "conf_int_full_97 = full_model.conf_int(alpha=0.03)\n",
    "\n",
    "schooling_ci = conf_int_full_97.loc['Schooling']\n",
    "alcohol_ci = conf_int_full_97.loc['Alcohol']\n",
    "\n",
    "print(\"\\nSchooling 97% confidence intervals:\", schooling_ci.values)\n",
    "print(\"Alcohol 97% confidence intervals:\", alcohol_ci.values)\n",
    "\n",
    "if schooling_ci[0] > 0 and schooling_ci[1] > 0:\n",
    "    print(\"Schooling has positive impact on the life expectancy.\")\n",
    "elif schooling_ci[0] < 0 and schooling_ci[1] < 0:\n",
    "    print(\"Schooling has negative impact on the life expectancy.\")\n",
    "else:\n",
    "    print(\"Schooling has no impact on the life expectancy.\")\n",
    "\n",
    "if alcohol_ci[0] > 0 and alcohol_ci[1] > 0:\n",
    "    print(\"Alcohol has positive impact on the life expectancy.\")\n",
    "elif alcohol_ci[0] < 0 and alcohol_ci[1] < 0:\n",
    "    print(\"Alcohol has negative impact on the life expectancy.\")\n",
    "else:\n",
    "    print(\"Alcohol has no impact on the life expectancy.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a309a61-4807-4593-88dd-97cae506f4c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "top7_vars: ['HIV/AIDS', 'Adult Mortality', 'Schooling', 'under-five deaths', 'infant deaths', 'BMI', 'Income composition of resources']\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:        Life expectancy   R-squared:                       0.791\n",
      "Model:                            OLS   Adj. R-squared:                  0.791\n",
      "Method:                 Least Squares   F-statistic:                     1583.\n",
      "Date:                Fri, 20 Sep 2024   Prob (F-statistic):               0.00\n",
      "Time:                        23:47:54   Log-Likelihood:                -8458.3\n",
      "No. Observations:                2928   AIC:                         1.693e+04\n",
      "Df Residuals:                    2920   BIC:                         1.698e+04\n",
      "Df Model:                           7                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===================================================================================================\n",
      "                                      coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------------\n",
      "HIV/AIDS                           -0.4662      0.019    -24.957      0.000      -0.503      -0.430\n",
      "Adult Mortality                    -0.0217      0.001    -25.879      0.000      -0.023      -0.020\n",
      "Schooling                           0.9089      0.043     21.071      0.000       0.824       0.994\n",
      "under-five deaths                  -0.0844      0.006    -13.363      0.000      -0.097      -0.072\n",
      "infant deaths                       0.1099      0.009     12.829      0.000       0.093       0.127\n",
      "BMI                                 0.0595      0.005     12.041      0.000       0.050       0.069\n",
      "Income composition of resources     7.5965      0.670     11.332      0.000       6.282       8.911\n",
      "const                              55.8930      0.425    131.471      0.000      55.059      56.727\n",
      "==============================================================================\n",
      "Omnibus:                      169.578   Durbin-Watson:                   0.620\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              700.440\n",
      "Skew:                          -0.045   Prob(JB):                    7.97e-153\n",
      "Kurtosis:                       5.394   Cond. No.                     1.94e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.94e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "p_values = full_model.pvalues.drop('const')\n",
    "\n",
    "sorted_p = p_values.sort_values()\n",
    "\n",
    "top7_vars = sorted_p.index[:7].tolist()\n",
    "print(\"\\ntop7_vars:\", top7_vars)\n",
    "\n",
    "X_small = X[top7_vars + ['const']]\n",
    "\n",
    "small_model = sm.OLS(y, X_small).fit()\n",
    "\n",
    "print(small_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8bfded5-4cdd-4c52-a798-6a4e404dbc2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        mean   mean_se  mean_ci_lower  mean_ci_upper  obs_ci_lower  \\\n",
      "0  89.576442  0.794559      87.528455      91.624429     78.167474   \n",
      "\n",
      "   obs_ci_upper  \n",
      "0    100.985409  \n"
     ]
    }
   ],
   "source": [
    "new_observation = {\n",
    "    'Year': 2008,\n",
    "    'Adult Mortality': 125,\n",
    "    'infant deaths': 94,\n",
    "    'Alcohol': 4.1,\n",
    "    'percentage_expenditure': 100,\n",
    "    'Hepatitis_B': 20,\n",
    "    'Measles': 13,\n",
    "    'BMI': 55,\n",
    "    'under-five deaths': 2,\n",
    "    'Polio': 12,\n",
    "    'Total_expenditure': 5.9,\n",
    "    'Diphtheria': 12,\n",
    "    'HIV/AIDS': 0.5,\n",
    "    'GDP': 5892,\n",
    "    'Population': 1.34e6,\n",
    "    'thinness_1_19_years': np.nan, \n",
    "    'thinness_5_9_years': np.nan,\n",
    "    'Income composition of resources': 0.9,\n",
    "    'Schooling': 18\n",
    "}\n",
    "\n",
    "new_obs_df = pd.DataFrame([new_observation])\n",
    "\n",
    "new_obs_df = sm.add_constant(new_obs_df,has_constant='add')\n",
    "\n",
    "X_new = new_obs_df[top7_vars + ['const']]\n",
    "\n",
    "prediction = small_model.get_prediction(X_new)\n",
    "pred_summary = prediction.summary_frame(alpha=0.01)\n",
    "\n",
    "print(pred_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ebf7aac-17fa-454f-8200-e95e5cb41f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "full_model_aic: 16521.085082746766\n",
      "small_model_aic: 16932.62646207667\n",
      "\n",
      "Full_model_aic is lower.\n"
     ]
    }
   ],
   "source": [
    "full_model_aic = full_model.aic\n",
    "small_model_aic = small_model.aic\n",
    "\n",
    "print(\"\\nfull_model_aic:\", full_model_aic)\n",
    "print(\"small_model_aic:\", small_model_aic)\n",
    "\n",
    "if small_model_aic < full_model_aic:\n",
    "    print(\"\\nSmall_model_aic is lower.\")\n",
    "else:\n",
    "    print(\"\\nFull_model_aic is lower.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca8976e9-c789-4ac4-b6e9-35d8d62b7e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Without Standardization ===\n",
      "K=1: MSE=44.5171, Time=0.0054 seconds\n",
      "K=2: MSE=46.0559, Time=0.0049 seconds\n",
      "K=3: MSE=41.5232, Time=0.0047 seconds\n",
      "K=4: MSE=40.8879, Time=0.0046 seconds\n",
      "K=5: MSE=42.2411, Time=0.0046 seconds\n",
      "K=6: MSE=43.8894, Time=0.0046 seconds\n",
      "K=7: MSE=43.9851, Time=0.0046 seconds\n",
      "K=8: MSE=42.8303, Time=0.0053 seconds\n",
      "K=9: MSE=44.0434, Time=0.0047 seconds\n",
      "K=10: MSE=45.6143, Time=0.0046 seconds\n",
      "K=11: MSE=45.7835, Time=0.0046 seconds\n",
      "K=12: MSE=45.8784, Time=0.0047 seconds\n",
      "K=13: MSE=45.7650, Time=0.0046 seconds\n",
      "K=14: MSE=46.5139, Time=0.0046 seconds\n",
      "K=15: MSE=46.5349, Time=0.0046 seconds\n",
      "K=16: MSE=48.1896, Time=0.0052 seconds\n",
      "K=17: MSE=49.1327, Time=0.0048 seconds\n",
      "K=18: MSE=48.9265, Time=0.0048 seconds\n",
      "K=19: MSE=50.1288, Time=0.0047 seconds\n",
      "K=20: MSE=51.0900, Time=0.0046 seconds\n",
      "Best K (No Standardization): 4 with MSE=40.8879\n",
      "\n",
      "=== With Standardization ===\n",
      "K=1: MSE=25.4693, Time=0.0048 seconds\n",
      "K=2: MSE=16.7776, Time=0.0049 seconds\n",
      "K=3: MSE=19.7349, Time=0.0047 seconds\n",
      "K=4: MSE=20.0199, Time=0.0054 seconds\n",
      "K=5: MSE=21.2268, Time=0.0050 seconds\n",
      "K=6: MSE=22.2554, Time=0.0048 seconds\n",
      "K=7: MSE=21.6547, Time=0.0048 seconds\n",
      "K=8: MSE=20.8683, Time=0.0047 seconds\n",
      "K=9: MSE=21.0368, Time=0.0047 seconds\n",
      "K=10: MSE=20.5081, Time=0.0052 seconds\n",
      "K=11: MSE=20.5842, Time=0.0053 seconds\n",
      "K=12: MSE=20.4433, Time=0.0052 seconds\n",
      "K=13: MSE=20.8555, Time=0.0050 seconds\n",
      "K=14: MSE=21.5664, Time=0.0047 seconds\n",
      "K=15: MSE=21.7233, Time=0.0047 seconds\n",
      "K=16: MSE=22.0933, Time=0.0047 seconds\n",
      "K=17: MSE=22.6631, Time=0.0050 seconds\n",
      "K=18: MSE=23.3725, Time=0.0051 seconds\n",
      "K=19: MSE=24.1986, Time=0.0050 seconds\n",
      "K=20: MSE=24.4539, Time=0.0047 seconds\n",
      "Best K (With Standardization): 2 with MSE=16.7776\n",
      "\n",
      "Standardization improved the performance.\n"
     ]
    }
   ],
   "source": [
    "# Problem 3: Implementing KNN regression\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from math import sqrt\n",
    "\n",
    "class KNNRegressor:\n",
    "\n",
    "    def __init__(self, n_neighbors):\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for index, test_point in enumerate(X):\n",
    "            distances = np.linalg.norm(self.X_train - test_point, axis=1)\n",
    "            neighbor_indices = np.argsort(distances)[:self.n_neighbors]\n",
    "            neighbor_values = self.y_train[neighbor_indices]\n",
    "            prediction = np.mean(neighbor_values)\n",
    "            predictions.append(prediction)\n",
    "        return predictions\n",
    "\n",
    "def mean_squared_error(y_true, y_pred):\n",
    "    return np.mean((np.array(y_true) - np.array(y_pred)) ** 2)\n",
    "\n",
    "def load_data(train_path, test_path):\n",
    "    # Load datasets\n",
    "    train_df = pd.read_csv(train_path)\n",
    "    test_df = pd.read_csv(test_path)\n",
    "\n",
    "    X_train = train_df.drop('medv', axis=1).values\n",
    "    y_train = train_df['medv'].values\n",
    "    X_test = test_df.drop('medv', axis=1).values\n",
    "    y_test = test_df['medv'].values\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "def standardize_data(X_train, X_test):\n",
    "    mean = X_train.mean(axis=0)\n",
    "    std = X_train.std(axis=0)\n",
    "    \n",
    "    # Avoid division by zero\n",
    "    std_replaced = np.where(std == 0, 1, std)\n",
    "    \n",
    "    X_train_std = (X_train - mean) / std_replaced\n",
    "    X_test_std = (X_test - mean) / std_replaced\n",
    "    return X_train_std, X_test_std\n",
    "\n",
    "def evaluate_knn(X_train, y_train, X_test, y_test, K_values):\n",
    "    results = {}\n",
    "    best_mse = float('inf')\n",
    "    best_K = None\n",
    "\n",
    "    for K in K_values:\n",
    "        knn = KNNRegressor(n_neighbors=K)\n",
    "        knn.fit(X_train, y_train)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        predictions = knn.predict(X_test)\n",
    "        end_time = time.time()\n",
    "        \n",
    "        mse = mean_squared_error(y_test, predictions)\n",
    "        running_time = end_time - start_time\n",
    "        \n",
    "        results[K] = {'MSE': mse, 'Time': running_time}\n",
    "        \n",
    "        if mse < best_mse:\n",
    "            best_mse = mse\n",
    "            best_K = K\n",
    "\n",
    "        print(f\"K={K}: MSE={mse:.4f}, Time={running_time:.4f} seconds\")\n",
    "\n",
    "    return results, best_K\n",
    "\n",
    "def main():\n",
    "    train_path = 'boston_housing_train.csv'\n",
    "    test_path = 'boston_housing_test.csv'\n",
    "\n",
    "    X_train, y_train, X_test, y_test = load_data(train_path, test_path)\n",
    "\n",
    "    K_values = list(range(1, 21))  # K from 1 to 20\n",
    "\n",
    "    print(\"=== Without Standardization ===\")\n",
    "    results_no_std, best_K_no_std = evaluate_knn(X_train, y_train, X_test, y_test, K_values)\n",
    "    print(f\"Best K (No Standardization): {best_K_no_std} with MSE={results_no_std[best_K_no_std]['MSE']:.4f}\")\n",
    "\n",
    "    print(\"\\n=== With Standardization ===\")\n",
    "    X_train_std, X_test_std = standardize_data(X_train, X_test)\n",
    "    results_std, best_K_std = evaluate_knn(X_train_std, y_train, X_test_std, y_test, K_values)\n",
    "    print(f\"Best K (With Standardization): {best_K_std} with MSE={results_std[best_K_std]['MSE']:.4f}\")\n",
    "\n",
    "    improvement = results_std[best_K_std]['MSE'] < results_no_std[best_K_no_std]['MSE']\n",
    "    if improvement:\n",
    "        print(\"\\nStandardization improved the performance.\")\n",
    "    else:\n",
    "        print(\"\\nStandardization did not improve the performance.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3f77ed-ca86-4c54-9d6b-0f073e34fc4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
